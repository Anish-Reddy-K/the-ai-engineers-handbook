---
title: "Training & Inference"
slug: "training-inference"
weight: 7
draft: true
---

The computational cost of training vs. inference. GPU/TPU requirements. Pre-training vs. fine-tuning. Model optimization: quantization, distillation, pruning. Deployment considerations: latency, throughput, cost. Batch vs. real-time inference.
